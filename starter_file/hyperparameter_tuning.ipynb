{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-ml\n",
      "  Downloading azure_ai_ml-1.12.1-py3-none-any.whl (8.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.3 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting strictyaml<2.0.0\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 79.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.1.9)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.65.0)\n",
      "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Collecting marshmallow<4.0.0,>=3.5\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting azure-storage-file-datalake<13.0.0\n",
      "  Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\n",
      "\u001b[K     |████████████████████████████████| 251 kB 81.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-storage-file-share<13.0.0\n",
      "  Downloading azure_storage_file_share-12.15.0-py3-none-any.whl (267 kB)\n",
      "\u001b[K     |████████████████████████████████| 267 kB 77.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: isodate in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.6.1)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (1.4.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (2.4.0)\n",
      "Requirement already satisfied: colorama<0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (4.17.3)\n",
      "Collecting pydash<7.0.6,>=6.0.0\n",
      "  Downloading pydash-7.0.5-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 89.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-ml) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (2.31.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.2)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (1.13.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (38.0.4)\n",
      "Requirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (23.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (1.3.10)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.3)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (5.12.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.4)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.11.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.0.0)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.22.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (1.15.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (3.12.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.20.3)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.18.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.59.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.7.0)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (2.21)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.5.0)\n",
      "\u001b[31mERROR: azure-storage-file-datalake 12.14.0 has requirement azure-core<2.0.0,>=1.28.0, but you'll have azure-core 1.26.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-storage-file-datalake 12.14.0 has requirement azure-storage-blob<13.0.0,>=12.19.0, but you'll have azure-storage-blob 12.13.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azure-storage-file-share 12.15.0 has requirement azure-core<2.0.0,>=1.28.0, but you'll have azure-core 1.26.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pydash 7.0.5 has requirement typing-extensions!=4.6.0,>=3.10, but you'll have typing-extensions 4.6.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: strictyaml, marshmallow, azure-storage-file-datalake, azure-storage-file-share, pydash, azure-ai-ml\n",
      "Successfully installed azure-ai-ml-1.12.1 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.15.0 marshmallow-3.20.1 pydash-7.0.5 strictyaml-1.7.3\n",
      "Requirement already satisfied: azure-identity in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.13.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (38.0.4)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (1.22.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (1.16.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.7.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal<2.0.0,>=1.20.0->azure-identity) (2.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal<2.0.0,>=1.20.0->azure-identity) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (4.6.0)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.20.0->azure-identity) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.20.0->azure-identity) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.20.0->azure-identity) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.20.0->azure-identity) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-ml\n",
    "!pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "gather": {
     "logged": 1704009512349
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "import requests\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core import Workspace, Dataset, Experiment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azure.ai.ml.entities import Environment, Model\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.core.compute import AmlCompute ,ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azure.ai.ml.sweep import BanditPolicy\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azure.ai.ml import MLClient, command\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "gather": {
     "logged": 1704009516021
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "#Create MLClient object, this object is like a Workspace handle\n",
    "\n",
    "ML_CLIENT = MLClient.from_config(DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1704009520404
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment_name = 'hyperdrive-exper'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1704009526822
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "\n",
      "Running\n"
     ]
    }
   ],
   "source": [
    "amlcompute_cluster_name = \"notebook247476\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',                                                           \n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gather": {
     "logged": 1704019023427
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n",
    "command_job_for_sweep = command(\n",
    "    code=\"./\",\n",
    "    command=\"python train.py --dataset_name ${{inputs.dataset_name}} --C ${{inputs.C}} --max_iter ${{inputs.max_iter}}\",\n",
    "    environment=Environment(image=\"mcr.microsoft.com/azureml/curated/responsibleai-ubuntu20.04-py38-cpu:38\"),\n",
    "    inputs={\n",
    "        \"dataset_name\": \"IRIS-Dataset\",\n",
    "        #define the search space for your hyperparameters\n",
    "        \"C\": Uniform(min_value=0.01, max_value=1),\n",
    "        \"max_iter\": Choice(values=[50, 100, 200]),\n",
    "    },\n",
    "    compute=\"cpu-cluster\",\n",
    ")\n",
    "\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=amlcompute_cluster_name, \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"Accuracy\",\n",
    "    goal=\"Maximize\",\n",
    "    early_termination_policy=early_termination_policy\n",
    ")\n",
    "\n",
    "sweep_job.set_limits(max_total_trials=20, max_concurrent_trials=10, timeout=7200)\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"hp-iris\"\n",
    "sweep_job.experiment_name = \"hp-iris\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep job on Iris dataset.\"\n",
    "\n",
    "\n",
    "# submit the sweep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1704019023455
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading odl_user_247476 (0.5 MBs): 100%|██████████| 497304/497304 [00:00<00:00, 3416504.22it/s]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Submit your experiment\n",
    "returned_sweep_job = ML_CLIENT.create_or_update(sweep_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "gather": {
     "logged": 1704019023486
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: olive_library_qpm1j0g79c\n",
      "Web View: https://ml.azure.com/runs/olive_library_qpm1j0g79c?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-247476/workspaces/quick-starts-ws-247476\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2023-12-31T11:00:20.076742][GENERATOR][INFO]Trying to sample '10' jobs from the hyperparameter space\n",
      "[2023-12-31T11:00:20.5389318Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_0' \n",
      "[2023-12-31T11:00:20.7782580Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_2' \n",
      "[2023-12-31T11:00:20.7770264Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_1' \n",
      "[2023-12-31T11:00:20.8918988Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_3' \n",
      "[2023-12-31T11:00:21.0252133Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_4' \n",
      "[2023-12-31T11:00:21.1242149Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_5' \n",
      "[2023-12-31T11:00:21.2348949Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_1' \n",
      "[2023-12-31T11:00:21.2285377Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_0' \n",
      "[2023-12-31T11:00:21.2320261Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_6' \n",
      "[2023-12-31T11:00:21.2783813Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_4' \n",
      "[2023-12-31T11:00:21.3610273Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_2' \n",
      "[2023-12-31T11:00:21.3105505Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_3' \n",
      "[2023-12-31T11:00:21.3578885Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_5' \n",
      "[2023-12-31T11:00:21.3762870Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_7' \n",
      "[2023-12-31T11:00:21.4513045Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_6' \n",
      "[2023-12-31T11:00:21.5512967Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_8' \n",
      "[2023-12-31T11:00:21.6317077Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_9' \n",
      "[2023-12-31T11:00:21.6347251Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_7' \n",
      "[2023-12-31T11:00:21.569137][GENERATOR][INFO]Successfully sampled '10' jobs, they will soon be submitted to the execution target.\n",
      "[2023-12-31T11:00:21.7896448Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_8' \n",
      "[2023-12-31T11:00:21.8555317Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_9' \n",
      "[2023-12-31T11:02:21.243219][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n",
      "[2023-12-31T11:02:21.5711258Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_10' \n",
      "[2023-12-31T11:02:21.7004697Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_11' \n",
      "[2023-12-31T11:02:21.8350037Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_10' \n",
      "[2023-12-31T11:02:21.8654838Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_12' \n",
      "[2023-12-31T11:02:21.9856824Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_13' \n",
      "[2023-12-31T11:02:22.0900357Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_11' \n",
      "[2023-12-31T11:02:21.922820][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n",
      "[2023-12-31T11:02:22.0843173Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_12' \n",
      "[2023-12-31T11:02:22.3108976Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_13' \n",
      "[2023-12-31T11:03:21.220888][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n",
      "[2023-12-31T11:03:21.5419103Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_14' \n",
      "[2023-12-31T11:03:21.7597323Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_14' \n",
      "[2023-12-31T11:03:21.7452168Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_15' \n",
      "[2023-12-31T11:03:21.8725261Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_16' \n",
      "[2023-12-31T11:03:21.9422362Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_17' \n",
      "[2023-12-31T11:03:21.9788044Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_15' \n",
      "[2023-12-31T11:03:21.853044][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n",
      "[2023-12-31T11:03:22.1240618Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_16' \n",
      "[2023-12-31T11:03:22.2345548Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_17' \n",
      "[2023-12-31T11:03:51.235339][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\n",
      "[2023-12-31T11:03:51.6597540Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_18' \n",
      "[2023-12-31T11:03:51.7893733Z][SCHEDULER][INFO]Scheduling job, id='olive_library_qpm1j0g79c_19' \n",
      "[2023-12-31T11:03:51.696173][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\n",
      "[2023-12-31T11:03:51.9062508Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_18' \n",
      "[2023-12-31T11:03:52.0369392Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olive_library_qpm1j0g79c_19' \n",
      "[2023-12-31T11:04:21.233757][GENERATOR][INFO]Max number of jobs '20' reached for experiment.\n",
      "[2023-12-31T11:04:21.368399][GENERATOR][INFO]All jobs generated.\n",
      "[2023-12-31T11:05:22.4685058Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: olive_library_qpm1j0g79c\n",
      "Web View: https://ml.azure.com/runs/olive_library_qpm1j0g79c?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-247476/workspaces/quick-starts-ws-247476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_CLIENT.jobs.stream(returned_sweep_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments.\n",
    "\n",
    "**I'm using SDK v2 sweepjob to run which doesn't support RunDetails.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare scoring function and MLClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "gather": {
     "logged": 1704019023197
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-247476/workspaces/quick-starts-ws-247476/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.olive_library_qpm1j0g79c_6/model to hp-deploy/named-outputs/mlflow_log_model_1902316930\n",
      "Downloading artifact azureml://subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-247476/workspaces/quick-starts-ws-247476/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.olive_library_qpm1j0g79c_6/hp to hp-deploy/named-outputs/mlflow_log_model_806180258\n",
      "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.olive_library_qpm1j0g79c_6 to hp-deploy/artifacts\n",
      "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.olive_library_qpm1j0g79c_6 to hp-deploy/hd-artifacts\n"
     ]
    }
   ],
   "source": [
    "# Download best model to local\n",
    "DEPLOY_PATH = \"hp-deploy\"\n",
    "os.makedirs(DEPLOY_PATH, exist_ok=True)\n",
    "MODEL_PATH = MODEL_NAME = \"model\"\n",
    "ML_CLIENT.jobs.download(name=returned_sweep_job.name, download_path=DEPLOY_PATH, all = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach the endpoint and model to workspace\n",
    "    * Register the endpoint\n",
    "    * Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1704017005013
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "import datetime\n",
    "endpoint_name = f\"hp-{datetime.datetime.now().strftime('%m%d%H%M%f')}\"\n",
    "ENDPOINT = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gather": {
     "logged": 1704017005030
    }
   },
   "outputs": [],
   "source": [
    "# Register the end point\n",
    "endpoint = ML_CLIENT.begin_create_or_update(ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "gather": {
     "logged": 1704017005046
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting endpoint deployed...\n",
      "Deployed endpoint hp-12311105866892 success. Status: Succeeded\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2)\n",
    "print(\"Waiting endpoint deployed...\")\n",
    "status = ML_CLIENT.online_endpoints.get(endpoint_name).provisioning_state\n",
    "while status == 'Creating':\n",
    "    time.sleep(1)\n",
    "    status = ML_CLIENT.online_endpoints.get(endpoint_name).provisioning_state\n",
    "\n",
    "if (status == \"Succeeded\"):\n",
    "    print(f\"Deployed endpoint {endpoint_name} success. Status: {status}\")\n",
    "else:\n",
    "    print(f\"Deployed endpoint {endpoint_name} failed. Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1704011517052
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading model (0.0 MBs): 100%|██████████| 2183/2183 [00:00<00:00, 60471.06it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'hp-model-1', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourceGroups/aml-quickstarts-247476/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-247476/models/hp-model-1/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/notebook247476/code/Users/odl_user_247476', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f99a4212b50>, 'serialize': <msrest.serialization.Serializer object at 0x7f99a4212610>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourceGroups/aml-quickstarts-247476/workspaces/quick-starts-ws-247476/datastores/workspaceblobstore/paths/LocalUpload/93f6bbbce0ff7f96922faa9288585a34/model', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'env': '{\\n  \"conda\": \"conda.yaml\",\\n  \"virtualenv\": \"python_env.yaml\"\\n}', 'loader_module': 'mlflow.sklearn', 'model_path': 'model.pkl', 'predict_fn': 'predict', 'python_version': '3.8.18'}, 'sklearn': {'code': '', 'pickled_model': 'model.pkl', 'serialization_format': 'cloudpickle', 'sklearn_version': '1.2.2'}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': 'Development'})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Model(\n",
    "        path=f\"{DEPLOY_PATH}/artifacts/{MODEL_PATH}\",\n",
    "        name=\"hp-model-2\",\n",
    "        type=AssetTypes.MLFLOW_MODEL\n",
    "    )\n",
    "ML_CLIENT.models.create_or_update(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Deployment object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1704011632789
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint hp-12311105866892 exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f998c9dcd00>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
    "deployment_name = \"snow-wolf\"\n",
    "DEPLOYMENT = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1\n",
    ")\n",
    "\n",
    "ML_CLIENT.begin_create_or_update(DEPLOYMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log.log\", \"w\") as f:\n",
    "\n",
    "    f.write(ML_CLIENT.online_deployments.get_logs(deployment_name, endpoint_name, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1704012103567
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting deployment deploying...\n",
      "..............................................................................................Deployed deployment snow-wolf success. Status: Succeeded\n",
      "."
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Waiting deployment deploying...\")\n",
    "status = ML_CLIENT.online_deployments.get(deployment_name, endpoint_name).provisioning_state\n",
    "while status == 'Updating':\n",
    "    time.sleep(1)\n",
    "    status = ML_CLIENT.online_deployments.get(deployment_name, endpoint_name).provisioning_state\n",
    "\n",
    "if (status == \"Succeeded\"):\n",
    "    print(f\"Deployed deployment {deployment_name} success. Status: {status}\")\n",
    "else:\n",
    "    print(f\"Deployed deployment {deployment_name} failed. Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7ff86498b490>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    }
   ],
   "source": [
    "ML_CLIENT.online_deployments.begin_delete(deployment_name, endpoint_name)\n",
    "ML_CLIENT.online_endpoints.begin_delete(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[2]'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data =  {\n",
    "  \"input_data\": {\n",
    "    \"columns\": [\n",
    "      \"SepalLengthCm\",\n",
    "      \"SepalWidthCm\",\n",
    "      \"PetalLengthCm\",\n",
    "      \"PetalWidthCm\"\n",
    "    ],\n",
    "    \"index\": [1],\n",
    "    \"data\": [[2, 3, 4, 5]]\n",
    "  },\n",
    "  \"params\": {}\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = ML_CLIENT.online_endpoints.get(endpoint_name).scoring_uri\n",
    "api_key = ML_CLIENT.online_endpoints.get_keys(endpoint_name)\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key.primary_key), 'azureml-model-deployment': 'snow-wolf' }\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get log\n",
    "ML_CLIENT.online_deployments.get_logs(name=\"AutoMlDeployment\", endpoint_name=endpoint_name, lines=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the service\n",
    "ML_CLIENT.online_endpoints.begin_delete(name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
